{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f3859f",
   "metadata": {},
   "source": [
    "# Autoencoders and POD on flow past cylinder (FPC) dataset\n",
    "\n",
    "Example notebook that displays the functionality of the built package for FPC and reproduces the results from the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a04531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the necessary external package imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Built package imports\n",
    "from ddganAE.utils import calc_pod\n",
    "from ddganAE.models import AAE, AAE_combined_loss, CAE, SVDAE\n",
    "from ddganAE.architectures.cae.D2 import *\n",
    "from ddganAE.architectures.svdae import *\n",
    "from ddganAE.architectures.discriminators import *\n",
    "from ddganAE.preprocessing import convert_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b332e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seeds for reproduceability\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7622d3",
   "metadata": {},
   "source": [
    "## Proper Orthogonal Decomposition (POD)\n",
    "\n",
    "First we try POD to benchmark the other moels against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots_grids = np.load(\"./../submodules/DD-GAN/data/processed/snaphsots_field_Velocity_new_4_2000steps.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f74ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data reshaping\n",
    "\n",
    "input_shape = (55, 42, 2)\n",
    "snapshots = convert_2d(snapshots_grids, input_shape, 2000)\n",
    "snapshots = np.array(snapshots).reshape(8000, *input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c62d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data and calculate POD\n",
    "\n",
    "# Could also try subtracting the mean but this does not give better results\n",
    "layer = preprocessing.Normalization(axis=None)\n",
    "layer.adapt(snapshots_grids)\n",
    "\n",
    "snapshots_norm = layer(snapshots_grids).numpy()\n",
    "\n",
    "coeffs, R, s = calc_pod(snapshots_norm, nPOD=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f75b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mean = 0\n",
    "for j in range(4):\n",
    "    recon = R @ coeffs[j]\n",
    "    for i in range(2000):\n",
    "        mean += tf.keras.losses.MSE(recon[:, i], snapshots_norm[j, :, i]).numpy()/8000\n",
    "\n",
    "print(\"POD MSE loss of the normalized dataset's reconstruction: \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78663ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reconstructed grids\n",
    "reconstructed = np.zeros((4, 4620, 2000))\n",
    "\n",
    "for i in range(4):\n",
    "    reconstructed[i, :, :] = R @ coeffs[i]\n",
    "\n",
    "# Undo normalization\n",
    "reconstructed = (reconstructed * np.sqrt(layer.variance.numpy()) + layer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a31773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to fit in interpolation (legacy) fortran code\n",
    "reconstructed = convert_2d(reconstructed, (55, 42, 2), 2000)\n",
    "reconstructed = np.array(reconstructed).swapaxes(1, 4)\n",
    "\n",
    "# Uncomment line below to save results\n",
    "# np.save(\"reconstruction_pod_10coeffs.npy\", reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6bcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a reconstruction to see if it visually corresponds to what we expect\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].contourf(reconstructed[0, 0, :, :, 100])\n",
    "ax[1].contourf(snapshots[100, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce77a4",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259dde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell does preprocessing, it is the same for the CAE and the AAE\n",
    "\n",
    "# Let's load in the data, split and reshape for the autoencoders\n",
    "snapshots_grids = np.load(\"./../submodules/DD-GAN/data/processed/snaphsots_field_Velocity_new_4_2000steps.npy\")\n",
    "\n",
    "# Some data reshaping\n",
    "input_shape = (55, 42, 2)\n",
    "snapshots = convert_2d(snapshots_grids, input_shape, 2000)\n",
    "snapshots = np.array(snapshots).reshape(8000, *input_shape)\n",
    "\n",
    "# Normalize and split dataset\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(snapshots)\n",
    "\n",
    "x_train, x_val = train_test_split(snapshots, test_size=0.1, random_state=seed)\n",
    "x_train = layer(x_train)\n",
    "x_val = layer(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fce7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameters set in this cell and the next correspond to the optimal hyperparameters from hyperparameter\n",
    "# optimization\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.98, beta_2=0.9)\n",
    "\n",
    "# Use this line to create a new model, select any from the list of models provided in the documentation or make\n",
    "# your own\n",
    "encoder, decoder = build_denser_omata_encoder_decoder(input_shape, 10, initializer, info=True, act='elu', dense_act='relu')\n",
    "\n",
    "# Use these lines to load a previously trained model\n",
    "# encoder = tf.keras.models.load_model(\"saved_model_cae/encoder\") \n",
    "# decoder = tf.keras.models.load_model(\"saved_model_cae/decoder\")\n",
    "\n",
    "cae = CAE(encoder, decoder, optimizer)\n",
    "cae.compile(input_shape, pi_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7df253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard logs the results, run `tensorboard --logdir logs` in this directory in a terminal with acces to\n",
    "# Tensorflow. Note that we can extract the MSE for the final report loss directly from tensorboard as the model\n",
    "# evaluates the validation dataset at every epoch\n",
    "cae.train(x_train, 200, val_data=x_val, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6a65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment lines below to save the model\n",
    "# !mkdir -p saved_model\n",
    "# cae.encoder.save('saved_model/encoder')\n",
    "# cae.decoder.save('saved_model/decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2190a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress all the samples\n",
    "snapshots = layer(snapshots)\n",
    "res = cae.predict(snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo normalization\n",
    "res = (res * np.sqrt(layer.variance.numpy()) + layer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a reconstruction to see if it visually corresponds to what we expect\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].contourf(res[92,:,:,1])\n",
    "ax[1].contourf(snapshots[92, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff718a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to how reconstruction legacy code wants it\n",
    "reconstruction = res.reshape((4, 2000, 55, 42, 2)).swapaxes(1, 4)\n",
    "np.save(\"cae_reconstruction.npy\", reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b29c6",
   "metadata": {},
   "source": [
    "## Adversarial Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell does preprocessing, it is the same for the CAE and the AAE\n",
    "\n",
    "# Let's load in the data, split and reshape for the autoencoders\n",
    "snapshots_grids = np.load(\"./../submodules/DD-GAN/data/processed/snaphsots_field_Velocity_new_4_2000steps.npy\")\n",
    "\n",
    "# Some data reshaping\n",
    "input_shape = (55, 42, 2)\n",
    "snapshots = convert_2d(snapshots_grids, input_shape, 2000)\n",
    "snapshots = np.array(snapshots).reshape(8000, *input_shape)\n",
    "\n",
    "# Normalize and split dataset\n",
    "layer = preprocessing.Normalization()\n",
    "layer.adapt(snapshots)\n",
    "\n",
    "x_train, x_val = train_test_split(snapshots, test_size=0.1, random_state=seed)\n",
    "x_train = layer(x_train)\n",
    "x_val = layer(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameters set in this cell and the next correspond to the optimal hyperparameters from hyperparameter\n",
    "# optimization\n",
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.8, beta_2=0.9)\n",
    "\n",
    "# Use this line to create a new model, select any from the list of models provided in the documentation or make\n",
    "# your own\n",
    "encoder, decoder = build_densest_omata_encoder_decoder(input_shape, 10, initializer, act='elu', dense_act='relu', info=True)\n",
    "discriminator = build_custom_discriminator(10, initializer, info=True)\n",
    "\n",
    "# Use these lines to load a previously trained model\n",
    "# encoder = tf.keras.models.load_model(\"saved_model_aae/encoder\")\n",
    "# decoder = tf.keras.models.load_model(\"saved_model_aae/decoder\")\n",
    "# discriminator = tf.keras.models.load_model(\"saved_model_aae/discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5092aab",
   "metadata": {},
   "source": [
    "### Separate losses\n",
    "\n",
    "Adversarial autoencoder with a separate loss for the discriminator, autoencoder, and generator. Each of these three are trained separately with this method.\n",
    "\n",
    "Execute either the following two cells or the two cells under \"combined losses\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5171ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE(encoder, decoder, discriminator, optimizer)\n",
    "aae.compile(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae.train(x_train, 200, val_data=x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec005ee",
   "metadata": {},
   "source": [
    "### Combined losses\n",
    "\n",
    "Aversarial autoencoder with a combined (and weighted) loss function for the discriminator and autoencoder, the generator is still trained independently. This model tends to perform significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265eed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae = AAE_combined_loss(encoder, decoder, discriminator, optimizer)\n",
    "aae.compile(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "aae.train(x_train, 200, val_data=x_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d67843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a loss value on the validation set\n",
    "res_val = aae.adversarial_autoencoder.predict(x_val)[0]\n",
    "np.mean(tf.keras.losses.MSE(res_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07addbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = layer(snapshots)\n",
    "res = aae.adversarial_autoencoder.predict(snapshots)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0be908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo normalization\n",
    "res = (res * np.sqrt(layer.variance.numpy()) + layer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].contourf(res[92,:,:,1])\n",
    "ax[1].contourf(snapshots[92, :, :, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to fit in interpolation (legacy) fortran code\n",
    "reconstruction = res.reshape((4, 2000, 55, 42, 2)).swapaxes(1, 4)\n",
    "np.save(\"aae_reconstruction.npy\", reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29bd97c",
   "metadata": {},
   "source": [
    "## SVD Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Load grids\n",
    "snapshots_grids = np.load(\"./../submodules/DD-GAN/data/processed/snaphsots_field_Velocity_new_4_2000steps.npy\")\n",
    "\n",
    "# Data normalization\n",
    "layer = preprocessing.Normalization(axis=None)\n",
    "layer.adapt(snapshots_grids)\n",
    "\n",
    "snapshots_grids = snapshots_grids.swapaxes(0, 2)\n",
    "\n",
    "x_train, x_val = train_test_split(snapshots_grids, test_size=0.1)\n",
    "x_train = layer(x_train).numpy().swapaxes(0, 2)\n",
    "x_val = layer(x_val).numpy().swapaxes(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=0.0005, beta_1=0.98, beta_2=0.99999)\n",
    "\n",
    "encoder, decoder = build_vinicius_encoder_decoder(100, 10, initializer, act='elu', dense_act='relu', info=False, reg=0, dropout=0.55, batchnorm=False)\n",
    "\n",
    "# encoder = tf.keras.models.load_model(\"saved_model_svdae/encoder\")\n",
    "# decoder = tf.keras.models.load_model(\"saved_model_svdae/decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403afee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdae = SVDAE(encoder, decoder, optimizer)\n",
    "svdae.compile(100, weight_loss=False)\n",
    "\n",
    "# Only set this when loading in the model\n",
    "# svdae.R = np.load(\"R_svdae.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04743d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdae.train(x_train, 200, val_data=x_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bbdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a loss value and create an array of output grids\n",
    "output = np.zeros((4, 2, 55, 42, 200))\n",
    "loss = 0\n",
    "for i in range(x_val.shape[0]):\n",
    "    for j in range(x_val.shape[2]):\n",
    "        original = x_val[i, :, j]\n",
    "        result = svdae.predict_single(original)\n",
    "        loss += tf.keras.losses.MSE(original, result)\n",
    "        result = (result * np.sqrt(layer.variance.numpy()) + layer.mean.numpy())\n",
    "        result = np.expand_dims(result,(0,2))\n",
    "        input_shape = (55, 42, 2)\n",
    "        result = convert_2d(result, input_shape, 1)\n",
    "        output[i, :, :, :, j] = np.moveaxis(np.array(result).reshape(55, 42, 2), 2, 0)\n",
    "        \n",
    "loss.numpy()/8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b16cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = x_val[2, :, 30]\n",
    "\n",
    "result = svdae.predict_single(original)\n",
    "result = np.expand_dims(result,(0,2))\n",
    "input_shape = (55, 42, 2)\n",
    "result = convert_2d(result, input_shape, 1)\n",
    "\n",
    "original = np.expand_dims(original,(0,2))\n",
    "original = convert_2d(original, input_shape, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].contourf(result[0][0, :, :, 0])\n",
    "ax[1].contourf(original[0][0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"svdae_reconstruction.npy\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd77d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "svdae.encoder.save('saved_model_svdae/encoder')\n",
    "svdae.decoder.save('saved_model_svdae/decoder')\n",
    "np.save('saved_model_svdae/R.npy', svdae.R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
